{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Notebook 1: Data Exploration and Baseline Model\n",
        "## CSE 546 Final Project - Flower Classification\n",
        "\n",
        "**Date**: November 2024  \n",
        "**Experiment**: 001 - Baseline  \n",
        "**Goal**: Establish baseline performance with KNN (k=5) without preprocessing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Imports and Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standard imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "import sys\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Add src to path\n",
        "sys.path.append('..')\n",
        "\n",
        "# Sklearn imports\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score, cross_validate\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\n",
        "\n",
        "# Local imports\n",
        "from src.preprocessing import load_data\n",
        "from src.evaluation import evaluate_model\n",
        "from src.utils import RANDOM_STATE, print_class_distribution, save_results\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(RANDOM_STATE)\n",
        "\n",
        "# Set plotting style\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Configure display\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.precision', 4)\n",
        "\n",
        "print(\"✓ All libraries imported successfully!\")\n",
        "print(f\"Random State: {RANDOM_STATE}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Loading and Verification\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "X_train, y_train, filenames, label_mapping, class_names = load_data(data_path='../data/')\n",
        "\n",
        "# Display basic information\n",
        "print(\"Dataset Information:\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Feature matrix shape: {X_train.shape}\")\n",
        "print(f\"Number of samples: {X_train.shape[0]}\")\n",
        "print(f\"Number of features: {X_train.shape[1]}\")\n",
        "print(f\"Number of classes: {len(np.unique(y_train))}\")\n",
        "print(\"\\nLabel mapping:\")\n",
        "print(label_mapping)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify data integrity\n",
        "print(\"Data Integrity Checks:\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Missing values in features: {X_train.isnull().sum().sum()}\")\n",
        "print(f\"Missing values in labels: {pd.Series(y_train).isnull().sum()}\")\n",
        "print(f\"Label range: {y_train.min()} to {y_train.max()}\")\n",
        "print(f\"Expected classes: [0, 1, 2, 3, 4]\")\n",
        "print(f\"Actual unique classes: {np.unique(y_train)}\")\n",
        "print(\"\\n✓ Data integrity verified!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Class Distribution Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print detailed class distribution\n",
        "print_class_distribution(y_train, class_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize class distribution\n",
        "class_counts = pd.Series(y_train).value_counts().sort_index()\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Bar plot\n",
        "axes[0].bar(class_counts.index, class_counts.values, color=sns.color_palette(\"husl\", 5))\n",
        "axes[0].set_xticks(class_counts.index)\n",
        "axes[0].set_xticklabels(class_names, rotation=45, ha='right')\n",
        "axes[0].set_xlabel('Flower Class', fontsize=12)\n",
        "axes[0].set_ylabel('Number of Samples', fontsize=12)\n",
        "axes[0].set_title('Class Distribution (Count)', fontsize=13, fontweight='bold')\n",
        "axes[0].grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Add count labels on bars\n",
        "for idx, count in enumerate(class_counts.values):\n",
        "    axes[0].text(idx, count + 15, str(count), ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
        "\n",
        "# Pie chart\n",
        "colors = sns.color_palette(\"husl\", 5)\n",
        "axes[1].pie(class_counts.values, labels=class_names, autopct='%1.1f%%', \n",
        "            startangle=90, colors=colors, textprops={'fontsize': 11})\n",
        "axes[1].set_title('Class Distribution (Percentage)', fontsize=13, fontweight='bold')\n",
        "\n",
        "plt.suptitle('Figure 1: Dataset Class Distribution Analysis', fontsize=14, fontweight='bold', y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Save figure\n",
        "from src.evaluation import save_figure\n",
        "save_figure(fig, 'figure1_class_distribution', report_num=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Feature Statistics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Basic feature statistics\n",
        "print(\"Feature Statistics Summary:\")\n",
        "print(\"=\" * 60)\n",
        "print(X_train.describe().loc[['mean', 'std', 'min', '25%', '50%', '75%', 'max']].iloc[:, :5])\n",
        "print(\"\\n(Showing first 5 features, all 512 features follow similar patterns)\")\n",
        "\n",
        "# Feature value ranges\n",
        "print(\"\\nFeature Value Ranges:\")\n",
        "print(f\"Overall min: {X_train.min().min():.4f}\")\n",
        "print(f\"Overall max: {X_train.max().max():.4f}\")\n",
        "print(f\"Overall mean: {X_train.mean().mean():.4f}\")\n",
        "print(f\"Overall std: {X_train.std().mean():.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Baseline Model Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set up cross-validation strategy\n",
        "cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=RANDOM_STATE)\n",
        "\n",
        "print(\"Cross-Validation Strategy:\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Method: Stratified K-Fold\")\n",
        "print(f\"Number of folds: 4\")\n",
        "print(f\"Shuffle: True\")\n",
        "print(f\"Random state: {RANDOM_STATE}\")\n",
        "print(\"\\n✓ Cross-validation configured\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Experiment 001: Baseline KNN (No Preprocessing)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create baseline KNN classifier\n",
        "knn_baseline = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "print(\"Experiment 001: Baseline Model\")\n",
        "print(\"=\" * 60)\n",
        "print(\"Configuration:\")\n",
        "print(f\"  - Classifier: K-Nearest Neighbors\")\n",
        "print(f\"  - K (neighbors): 5\")\n",
        "print(f\"  - Weights: uniform\")\n",
        "print(f\"  - Metric: euclidean (default)\")\n",
        "print(f\"  - Preprocessing: None\")\n",
        "print(\"\\nRunning cross-validation...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate baseline model\n",
        "baseline_results, baseline_scores = evaluate_model(\n",
        "    knn_baseline, X_train, y_train, cv, model_name=\"Baseline KNN (k=5)\"\n",
        ")\n",
        "\n",
        "print(\"\\nBaseline Results:\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Training Accuracy:   {baseline_results['train_acc']:.4f} (±{baseline_results['train_acc_std']:.4f})\")\n",
        "print(f\"Validation Accuracy: {baseline_results['val_acc']:.4f} (±{baseline_results['val_acc_std']:.4f})\")\n",
        "print(f\"ROC-AUC (OvR):       {baseline_results['roc_auc']:.4f}\")\n",
        "print(f\"F1-Score (macro):    {baseline_results['f1_macro']:.4f}\")\n",
        "print(f\"Overfitting Gap:     {baseline_results['overfit_gap']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Detailed Fold Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze performance across folds\n",
        "print(\"Fold-by-Fold Analysis:\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\nAccuracy per fold:\")\n",
        "for i, acc in enumerate(baseline_scores['test_accuracy'], 1):\n",
        "    print(f\"  Fold {i}: {acc:.4f}\")\n",
        "\n",
        "print(f\"\\nConsistency Analysis:\")\n",
        "print(f\"  Mean: {baseline_scores['test_accuracy'].mean():.4f}\")\n",
        "print(f\"  Std:  {baseline_scores['test_accuracy'].std():.4f}\")\n",
        "print(f\"  Min:  {baseline_scores['test_accuracy'].min():.4f}\")\n",
        "print(f\"  Max:  {baseline_scores['test_accuracy'].max():.4f}\")\n",
        "print(f\"  Range: {baseline_scores['test_accuracy'].max() - baseline_scores['test_accuracy'].min():.4f}\")\n",
        "\n",
        "if baseline_scores['test_accuracy'].std() < 0.02:\n",
        "    print(\"\\n✓ Good consistency across folds (std < 0.02)\")\n",
        "else:\n",
        "    print(\"\\n⚠ Moderate variability across folds\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize fold performance\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Fold comparison\n",
        "folds = np.arange(1, 5)\n",
        "axes[0].bar(folds, baseline_scores['test_accuracy'], alpha=0.7, color='steelblue', edgecolor='black')\n",
        "axes[0].axhline(y=baseline_scores['test_accuracy'].mean(), color='red', \n",
        "                linestyle='--', linewidth=2, label=f\"Mean: {baseline_scores['test_accuracy'].mean():.4f}\")\n",
        "axes[0].set_xlabel('Fold Number', fontsize=12)\n",
        "axes[0].set_ylabel('Accuracy', fontsize=12)\n",
        "axes[0].set_title('Accuracy Across CV Folds', fontsize=13, fontweight='bold')\n",
        "axes[0].set_xticks(folds)\n",
        "axes[0].legend(fontsize=10)\n",
        "axes[0].grid(axis='y', alpha=0.3)\n",
        "axes[0].set_ylim([0.6, 0.85])\n",
        "\n",
        "# Metric comparison\n",
        "metrics = ['Accuracy', 'ROC-AUC', 'F1-Score']\n",
        "values = [\n",
        "    baseline_results['val_acc'],\n",
        "    baseline_results['roc_auc'],\n",
        "    baseline_results['f1_macro']\n",
        "]\n",
        "axes[1].bar(metrics, values, alpha=0.7, color=['steelblue', 'coral', 'seagreen'], edgecolor='black')\n",
        "axes[1].set_ylabel('Score', fontsize=12)\n",
        "axes[1].set_title('Baseline Performance Metrics', fontsize=13, fontweight='bold')\n",
        "axes[1].grid(axis='y', alpha=0.3)\n",
        "axes[1].set_ylim([0.6, 1.0])\n",
        "\n",
        "# Add value labels on bars\n",
        "for i, v in enumerate(values):\n",
        "    axes[1].text(i, v + 0.02, f'{v:.4f}', ha='center', va='bottom', \n",
        "                 fontsize=10, fontweight='bold')\n",
        "\n",
        "plt.suptitle('Figure 2: Baseline Model Performance Analysis', \n",
        "             fontsize=14, fontweight='bold', y=1.00)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "save_figure(fig, 'figure2_baseline_performance', report_num=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Save Results and Update Tracker\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare results for saving\n",
        "experiment_001 = {\n",
        "    'experiment_id': '001',\n",
        "    'description': 'Baseline KNN (k=5, no preprocessing)',\n",
        "    'model': 'KNeighborsClassifier',\n",
        "    'configuration': {\n",
        "        'n_neighbors': 5,\n",
        "        'weights': 'uniform',\n",
        "        'metric': 'euclidean',\n",
        "        'preprocessing': None\n",
        "    },\n",
        "    'cv_strategy': 'StratifiedKFold(n_splits=4, shuffle=True, random_state=42)',\n",
        "    'results': baseline_results,\n",
        "    'cv_scores': {\n",
        "        'test_accuracy': baseline_scores['test_accuracy'].tolist(),\n",
        "        'test_roc_auc_ovr': baseline_scores['test_roc_auc_ovr'].tolist(),\n",
        "        'test_f1_macro': baseline_scores['test_f1_macro'].tolist()\n",
        "    },\n",
        "    'status': 'completed'\n",
        "}\n",
        "\n",
        "# Save results\n",
        "save_results(experiment_001, 'baseline_results.pkl', results_dir='../results/preprocessing')\n",
        "\n",
        "print(\"\\n✓ Experiment 001 completed successfully!\")\n",
        "print(f\"\\nBaseline Performance Summary:\")\n",
        "print(f\"  - CV Accuracy: {baseline_results['val_acc']:.4f}\")\n",
        "print(f\"  - This establishes our baseline for improvement\")\n",
        "print(f\"\\nNext Steps:\")\n",
        "print(f\"  1. Test normalization methods (StandardScaler, MinMaxScaler, RobustScaler)\")\n",
        "print(f\"  2. Apply PCA with different component options\")\n",
        "print(f\"  3. Implement feature selection methods\")\n",
        "print(f\"  4. Optimize individual classifiers\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Log to experiment tracker\n",
        "from src.utils import log_experiment\n",
        "\n",
        "log_experiment(\n",
        "    exp_num=1,\n",
        "    description=\"Baseline KNN (k=5) without preprocessing\",\n",
        "    config=experiment_001['configuration'],\n",
        "    results=baseline_results,\n",
        "    log_file='../experiment_tracker.md'\n",
        ")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
