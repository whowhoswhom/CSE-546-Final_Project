# CSE 546 Final Project - Repository Overview
## Flower Classification with Machine Learning

**Repository**: https://github.com/whowhoswhom/CSE-546-Final_ProjectV1  
**Course**: CSE 546 - Introduction to Machine Learning  
**Professor**: H. Frigui  
**Semester**: Fall 2024  

---

## ğŸ¯ Project Mission
Develop a robust 5-class flower classification system using traditional machine learning techniques, demonstrating deep understanding of preprocessing, optimization, and ensemble methods through systematic experimentation and analysis.

---

## ğŸ“Š Dataset Overview
- **Training Samples**: 4,065 images (pre-extracted features)
- **Feature Dimensions**: 512
- **Classes**: 5 flower types
  ```
  0: Daisy     (757 samples, 18.6%)
  1: Dandelion (1,045 samples, 25.7%)
  2: Rose      (560 samples, 13.8%)  â† Minority class
  3: Sunflower (726 samples, 17.9%)
  4: Tulip     (977 samples, 24.0%)
  ```
- **Challenge**: Class imbalance ratio 1.87:1 (Dandelion:Rose)

---

## ğŸ“ Repository Structure

```
CSE-546-Final_ProjectV1/
â”‚
â”œâ”€â”€ README.md                 # Public repository description
â”œâ”€â”€ repo.md                   # This file - Internal project context
â”œâ”€â”€ .cursorrules             # Cursor AI context and constraints
â”œâ”€â”€ .gitignore               # Git ignore rules
â”‚
â”œâ”€â”€ data/                    # Dataset files (git-ignored if large)
â”‚   â”œâ”€â”€ flower_train_features.csv
â”‚   â”œâ”€â”€ flower_train_labels.csv
â”‚   â”œâ”€â”€ flower_train_filenames.csv
â”‚   â”œâ”€â”€ flower_label_mapping.csv
â”‚   â””â”€â”€ test_features.csv    # (Added Dec 3)
â”‚
â”œâ”€â”€ docs/                    # Project documentation
â”‚   â”œâ”€â”€ task.md             # Project objectives
â”‚   â”œâ”€â”€ rules.md            # Requirements and constraints
â”‚   â”œâ”€â”€ project_requirements.md  # Original assignment
â”‚   â”œâ”€â”€ experiment_tracker.md    # Experiment logging
â”‚   â””â”€â”€ project_setup.md    # Setup guide
â”‚
â”œâ”€â”€ notebooks/               # Jupyter notebooks (numbered sequence)
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb
â”‚   â”œâ”€â”€ 02_preprocessing_experiments.ipynb
â”‚   â”œâ”€â”€ 03_individual_classifiers.ipynb
â”‚   â”œâ”€â”€ 04_ensemble_methods.ipynb
â”‚   â”œâ”€â”€ 05_final_model_selection.ipynb
â”‚   â””â”€â”€ 06_test_predictions.ipynb
â”‚
â”œâ”€â”€ src/                     # Source code modules
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ preprocessing.py    # Preprocessing functions
â”‚   â”œâ”€â”€ classifiers.py      # Classifier implementations
â”‚   â”œâ”€â”€ evaluation.py       # Evaluation and plotting
â”‚   â”œâ”€â”€ ensemble.py         # Ensemble methods
â”‚   â””â”€â”€ utils.py           # Utility functions
â”‚
â”œâ”€â”€ results/                 # Experiment results and outputs
â”‚   â”œâ”€â”€ preprocessing/      # Preprocessing experiments
â”‚   â”œâ”€â”€ classifiers/        # Individual classifier results
â”‚   â”œâ”€â”€ ensemble/          # Ensemble method results
â”‚   â””â”€â”€ figures/           # All figures for reports
â”‚       â”œâ”€â”€ report1/       # Figures for Report 1
â”‚       â””â”€â”€ final/         # Figures for Final Report
â”‚
â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ checkpoints/        # Intermediate model saves
â”‚   â”œâ”€â”€ best_model.pkl      # Final selected model
â”‚   â””â”€â”€ model_comparison.json  # Performance comparison
â”‚
â”œâ”€â”€ reports/                 # Report materials
â”‚   â”œâ”€â”€ report1/
â”‚   â”‚   â”œâ”€â”€ report1.docx
â”‚   â”‚   â””â”€â”€ figures/
â”‚   â””â”€â”€ final_report/
â”‚       â”œâ”€â”€ final_report.docx
â”‚       â”œâ”€â”€ recording_link.txt
â”‚       â””â”€â”€ figures/
â”‚
â””â”€â”€ requirements.txt         # Python dependencies
```

---

## ğŸ”„ Git Workflow & Version Control

### Branch Strategy
```
main (protected)
â”œâ”€â”€ development (active work)
â”œâ”€â”€ feature/preprocessing
â”œâ”€â”€ feature/classifiers
â”œâ”€â”€ feature/ensemble
â”œâ”€â”€ report/report1
â””â”€â”€ report/final
```

### Commit Convention
```bash
# Format: [TYPE] Component: Description

[FEAT] Preprocessing: Add PCA variance analysis
[FIX] KNN: Correct cross-validation scoring
[DOC] Report1: Add learning curve analysis
[EXP] SVM: Test polynomial kernel with C=10
[PLOT] Ensemble: Generate correlation heatmap
```

### Types:
- `[FEAT]` - New feature/functionality
- `[FIX]` - Bug fix
- `[DOC]` - Documentation/report updates
- `[EXP]` - Experiment (include results in message)
- `[PLOT]` - Figure/visualization generation
- `[OPT]` - Optimization/performance improvement
- `[TEST]` - Test data predictions

### Tagging Milestones
```bash
git tag -a baseline-complete -m "Baseline KNN: 73.5% accuracy"
git tag -a report1-submission -m "Report 1 submitted: Nov 21"
git tag -a best-model-v1 -m "Best model: SVM RBF C=10, 89.3%"
git tag -a final-submission -m "Final submission: Dec 5"
```

---

## ğŸ“ˆ Development Status

### Current Phase: **Preprocessing & Initial Classifiers**

#### Progress Tracker
```
Overall Progress: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘ 60%

âœ… Completed:
â”œâ”€â”€ [x] Project setup and documentation
â”œâ”€â”€ [x] Data exploration and visualization
â”œâ”€â”€ [x] Baseline model (KNN, no preprocessing)
â”œâ”€â”€ [x] Normalization comparison
â””â”€â”€ [x] PCA analysis

ğŸ”„ In Progress:
â”œâ”€â”€ [ ] Feature selection experiments
â”œâ”€â”€ [ ] KNN full optimization
â””â”€â”€ [ ] SVM parameter tuning

ğŸ“‹ Upcoming:
â”œâ”€â”€ [ ] Random Forest optimization
â”œâ”€â”€ [ ] MLP implementation
â”œâ”€â”€ [ ] Ensemble methods (Stacking, AdaBoost)
â””â”€â”€ [ ] Final model selection
```

### Key Metrics Dashboard
| Metric | Baseline | Current Best | Target | Status |
|--------|----------|--------------|--------|---------|
| CV Accuracy | 73.5% | 86.2% | 90%+ | ğŸ”„ |
| ROC-AUC | 0.892 | 0.941 | 0.95+ | ğŸ”„ |
| F1-Macro | 0.728 | 0.859 | 0.88+ | ğŸ”„ |
| Overfitting Gap | 15.3% | 3.2% | <5% | âœ… |

---

## ğŸ§ª Experiment Registry

### Best Configurations Found
```python
# Best Preprocessing
Pipeline([
    ('scaler', StandardScaler()),
    ('pca', PCA(n_components=100))
])

# Best KNN
KNeighborsClassifier(
    n_neighbors=7,
    weights='distance',
    metric='euclidean'
)

# Best SVM (pending)
SVC(
    C=10,
    kernel='rbf',
    gamma='scale',
    probability=True
)
```

### Failed Experiments (Learning Points)
- âŒ PCA with 50 components: Too much information loss
- âŒ Polynomial kernel degree>3: Overfitting
- âŒ No scaling with SVM: Poor convergence

---

## ğŸ“ Key Deadlines & Deliverables

| Date | Deliverable | Status | Points |
|------|------------|---------|---------|
| Nov 21 | Report 1 (50% experiments) | ğŸ”„ In Progress | 20 pts |
| Dec 3 | Test predictions | â³ Waiting | 30 pts |
| Dec 5 | Final report | â³ Waiting | 50 pts |
| Dec 5 | Recording (<15 min) | â³ Waiting | - |
| Dec 5 | Notebook submission | â³ Waiting | - |

---

## ğŸ› ï¸ Development Guidelines

### For Every New Experiment
1. Create new branch: `git checkout -b exp/experiment-name`
2. Update `experiment_tracker.md` with configuration
3. Run experiment and save results to `results/`
4. Generate required plots to `results/figures/`
5. Commit with descriptive message including key metrics
6. Merge to development if successful

### Before Each Commit
- [ ] Code runs without errors
- [ ] Results saved to appropriate directory
- [ ] Experiment logged in tracker
- [ ] Figures generated and numbered
- [ ] Documentation updated if needed

### Code Quality Checklist
- [ ] Functions have docstrings
- [ ] Complex operations commented
- [ ] Random state set to 42
- [ ] Pipeline approach used
- [ ] Cross-validation with k=4
- [ ] Multiple metrics evaluated

---

## ğŸš€ Quick Commands

### Setup Environment
```bash
# Clone repository
git clone https://github.com/whowhoswhom/CSE-546-Final_ProjectV1.git
cd CSE-546-Final_ProjectV1

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### Run Experiments
```python
# Standard experiment execution
python -m notebooks.02_preprocessing_experiments
python -m notebooks.03_individual_classifiers

# Generate all figures for report
python src/evaluation.py --generate-all-figures --output results/figures/report1/
```

### Git Operations
```bash
# Start new experiment
git checkout development
git pull origin development
git checkout -b exp/adaboost-optimization

# Save experiment results
git add results/ notebooks/
git commit -m "[EXP] AdaBoost: Best config n_est=100, lr=0.5, acc=87.3%"

# Prepare for submission
git checkout report/report1
git merge development
git tag -a report1-ready -m "Report 1 ready for submission"
```

---

## ğŸ“Š Results Summary (Auto-Updated)

### Latest Experiment Results
| Exp# | Date | Method | Best Config | CV Acc | Status |
|------|------|--------|-------------|---------|---------|
| 001 | 11/15 | Baseline KNN | k=5, no scaling | 73.5% | âœ… |
| 002 | 11/16 | KNN + StandardScaler | k=7 | 81.2% | âœ… |
| 003 | 11/16 | KNN + PCA | k=7, n=100 | 83.4% | âœ… |
| 004 | 11/17 | SVM RBF | C=1, scale | 86.2% | âœ… |
| 005 | 11/18 | Feature Selection | k=200, f_classif | 82.1% | âœ… |
| ... | ... | ... | ... | ... | ... |

### Model Performance Ranking
1. **SVM (RBF)**: 86.2% accuracy, 0.941 ROC-AUC
2. **KNN (optimized)**: 83.4% accuracy, 0.918 ROC-AUC
3. **Random Forest**: [Pending]
4. **MLP**: [Pending]

---

## ğŸ”— Important Links

- **Course Materials**: [Blackboard/Canvas link]
- **Original Dataset**: https://www.kaggle.com/datasets/alxmamaev/flowers-recognition
- **Repository**: https://github.com/whowhoswhom/CSE-546-Final_ProjectV1
- **Previous Homeworks Reference**: [HW1-5 solutions in /mnt/project/]

---

## ğŸ’¡ Context for Cursor AI

### When Working on This Project:
1. **Always check** `docs/rules.md` for requirements
2. **Reference** `docs/experiment_tracker.md` for experiment history
3. **Follow** patterns from successful experiments
4. **Use** 4-fold CV and pipelines consistently
5. **Generate** numbered figures for all results
6. **Document** decisions and justifications
7. **Focus on** understanding over raw performance

### Key Constraints:
- Only scikit-learn (no deep learning)
- 4-fold cross-validation mandatory
- Must use pipelines
- All 3 metrics required (accuracy, ROC-AUC, F1)
- Maximum 15 pages for final report
- Recording maximum 15 minutes

### Professor's Priorities:
1. Systematic experimentation
2. Clear justifications for choices
3. Understanding of overfitting/underfitting
4. Professional presentation
5. Use of course concepts

---

## ğŸ“§ Contact & Collaboration

**Project Owner**: Toni (Jose Fuentes)  
**Course**: CSE 546 - Introduction to Machine Learning  
**Institution**: University of Louisville  
**Semester**: Fall 2024  

---

## ğŸ“ Notes Section

### Current Focus
- Completing preprocessing experiments for Report 1
- Optimizing KNN and SVM thoroughly
- Preparing learning curve visualizations

### Blockers/Issues
- None currently

### Next Steps
1. Complete feature selection comparison
2. Finalize KNN optimization
3. Start Random Forest implementation
4. Begin Report 1 writing

---

*Last Updated: November 2024*  
*Auto-sync with experiment_tracker.md for latest results*
